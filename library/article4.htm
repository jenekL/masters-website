<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Николенко А.А.,Котляр А.В., Тьен Т.К. Нгуен, -
        Обнаружение текстовых областей и выделение символов на изображениях с неоднородным фоном</title>

    <link rel="stylesheet" type="text/css" href="../css/files/articles.css">
</head>
<body>
<div id="maintext"><a href="index.htm">Назад в библиотеку</a>
    <br>
    <hr>
    <h1>Обнаружение текстовых областей и выделение символов на изображениях с неоднородным фоном</h1>
    <p><b>Автор:</b>
        Николенко А.А.,Котляр А.В., Тьен Т.К. Нгуен<br></p>
    <p><b>Источник:</b>
        Праці Одеського політехнічного університету 2013 //Вип. 1(40), с. 55-60.</p>
</div>
<div align="left">
    <p><b><i>
        А.О. Ніколенко, А.В. Котляр, Тьєн Т.К. Нгуєн. Виявлення текстових областей та виділення символів на зображеннях
        з неоднорідним фоном.</i></b>
        Розглянута задача виявлення текстових областей та виділення
        символів на зображеннях з неоднорідним фоном. Запропоновано
        метод виявлення текстових областей та виділення символів на
        зображеннях з неоднорідним фоном на основі алгоритму перетворення
        по товщині штриха символу тексту з використанням перетворення
        по товщині штриха символу тексту. Запропонований метод дозволив
        виявити та виділити в середньому 85 % символів тексту на зображеннях
        з неоднорідним фоном незалежно від мови та розміру шрифту.</p>
    <p>
        <b><i>Ключові слова:</i></b>
        обробка зображень, виділення символів, текстові області, перетворення по товщині штриха.</p>
    <p><b><i>
        А.А. Николенко, А.В. Котляр, Тьен Т.К. Нгуен. Обнаружение текстовых областей и выделение символов на
        изображениях с неоднородным фоном.</i></b>
        Рассмотрена задача обнаружения текстовых областей и выделения
        символов на изображениях с неоднородным фоном. Предложен метод
        обнаружения текстовых областей и выделения символов на изображениях
        с неоднородным фоном на основе алгоритма преобразования по толщине
        штриха символа текста. Предложенный метод позволил обнаружить и выделить
        в среднем 85 % символов текста на изображениях независимо от языка и размера шрифта.</p>
    <p>
        <b><i>Ключевые
            слова:</i></b>
        обработка изображений, выделение символов, текстовые области, преобразование по толщине штриха.</p>
    <p><b><i>
        A.A. Nikolenko, A.V. Kotlyar, Tien T.K. Nguyen. Text regions detection and symbol extraction in images with
        non-uniform background.</i></b>
        The problem of text regions detection and symbol extraction in images with non-uniform
        background was considered. The method of text regions detection and symbol extraction
        in images with non-uniform background based on algorithm of the stroke width transform
        of text symbol was proposed. The proposed method can detect and extract on average 85%
        of text characters in images regardless of the language and font size.</p>
    <p>
        <b><i>Keywords:</i></b>
        image processing, symbol extraction, text regions, stroke width transform.</p>

    <p>С каждым днем возрастает количество воспринимаемой и анализируемой
        человеком текстовой информации, нацеленной на информирование его в различных
        жизненных ситуациях. Объявления, вывески, надписи, визитные карточки,
        номерные знаки транспортных средств – лишь краткий перечень форм представления
        такой информации. С ростом количества информации назревает и вопрос –
        как автоматизировать и улучшить процесс восприятия информации человеком
        с помощью информационных технологий? В таких условиях весьма актуальной
        является разработка методик и алгоритмов обработки визуальной информации
        с последующим использованием в информационных системах различного назначения.
        Одним из видов таких систем являются системы автоматического распознавания текста.</p>
    <p>Базовой процедурой, применяемой на первоначальном этапе обработки в таких системах,
        является обнаружение текстовых областей. Существует множество алгоритмов и методов для ее
        выполнения, однако до настоящего времени нет окончательного решения этой задачи.</p>
    <p>Существующие методы обнаружения текстовых областей на изображениях можно условно
        разделить на три категории: текстурные, методы на основе областей и гибридные.
        Текстурные рассматривают текст как особый тип текстуры и используют для обнаружения
        такие его характеристики как локальная интенсивность или вейвлет-коэффициенты [1…3].
        Эти методы в основном определяют текстовые области, строки и столбцы которых параллельны
        соответствующим координатным осям. Методы на основе областей [4, 5] сначала находят
        кандидатов в текстовые области, используя выделение контуров или кластеризацию, а
        затем проводят фильтрацию областей, используя эвристические правила для отсеивания лишних.
        Третья категория, гибридные методы, представляют собой смесь методов первых двух категорий [5, 6].</p>
    <p>Перечисленные методы дают хорошие результаты лишь при экспериментальной оценке многих параметров
        (например, соотношение интенсивности текста и фона, размер шрифта и т.д). Это отрицательно сказывается
        на быстродействии самих методов либо сужает область их применения. В то же время, нельзя утверждать,
        что на сегодняшний день уже исчерпаны все возможные средства для выделения отличительных особенностей
        текстовых областей, используемые для обнаружения последних на изображениях с последующим выделением
        символов.</p>
    <p>В данной работе при анализе текстовых областей предлагается использовать такую характеристику
        как толщина штриха символа текста [3, 6]. Она основывается на априорных знаниях о том, что в пределах
        одной текстовой области (надписи, строки текста) толщина штриха символа текста и соотношение высоты/ширины
        символа остаются примерно неизменными.</p>
    <p><i>Целью данной работы</i> является разработка метода обнаружения текстовых областей и выделения
        символов на изображениях с неоднородным фоном, на основе алгоритма преобразования по толщине штриха символа
        текста.</p>
    <p>Исходное изображение, как правило, может иметь ряд искажений из-за наличия шума, низкого разрешения,
        бликов, недостаточной или излишней экспозиции и т.д. Всё это снижает вероятность обнаружения текстовой
        области и последующего выделения символов на изображениях.</p>
    <p>Для обнаружения текстовых областей и выделения символов на изображениях воспользуемся алгоритмом
        SWT (от английского Stroke Width Transform – преобразование по толщине штриха), первоначально предложенным в
        [6].
        Данный алгоритм использует толщину штриха символа текста, которая практически не меняется в пределах текстовой
        области изображения и, следовательно, является подходящей характеристикой для обнаружения текстовых
        областей.</p>
    <p>Общая схема метода обнаружения текстовых областей и выделения символов на изображениях с неоднородным фоном,
        основанного на методах и алгоритмах, предложенных в [3, 6], представлена на рис. 1.</p>
    <p>Реализация метода требует выполнения следующих этапов: предварительная обработка изображения,
        SWT-преобразование, фильтрация и объединение компонент.</p>
    <p></p>
    <h3>Этап 1. Предварительная обработка изображения.</h3>
    <p>Предварительная обработка изображения проводится по схеме (рис. 1): исходное изображение переводится
        из цветного в оттенки серого, затем полученное изображение сглаживается с использованием фильтра Гаусса
        апертурой 3 x 3 либо 5 x 5.</p>
    <p>После сглаживания изображения к нему применяется детектор границ Канни. Полученное с помощью детектора
        изображение инвертируется и сохраняется в памяти. В дальнейшем копия этого изображения сглаживается фильтром
        Гаусса апертурой 3 x 3 либо 5 x 5 с целью поиска нормали к контуру искомого символа в данной точке.</p>
    <img src="images/4/1.jpg"
                          alt="Общая схема метода обнаружения текстовых областей и выделение символов на изображениях с неоднородным фоном"
                          class="center">
        <p class="caption">Рисунок 1 – Общая схема метода обнаружения текстовых областей и выделение символов на
            изображениях с неоднородным фоном</p>
    </div>
    <h3>Этап 2. Выполнение SWT-преобразования изображения.</h3>
    <p>SWT-преобразование изображения реализуется по следующему алгоритму (рис. 2).</p>

<img src="images/4/2.jpg" alt="Блок-схема алгоритма SWT-обработки изображения" class="center">
        <p class="caption">Рисунок 2 – Блок-схема алгоритма SWT-обработки изображения</p>

    <br>
    <p>Шаг 1. Выбирается пиксель контурного изображения. Его координаты сохраняются в памяти как P1.
        В зарезервированном изображении с размытым контуром находится пиксель, соответствующий этим
        координатам, его окрестности проверяются на наибольшую (если текст светлее фона) либо наименьшую (в противном
        случае) интенсивность.
        Координаты этого пикселя также сохраняются в память (как P2).</p>
    <p>Шаг 2. Проводится луч из пикселя с координатами P1 в направлении пикселя с координатами P2.
        Если построенный луч пересекает любой необработанный пиксель контура, либо достигает границы изображения –
        он заполняется пикселями определенной интенсивности, рассчитываемой исходя из длины получившегося отрезка.</p>
    <p>Шаг 3. Повторяются шаги 1…2 до тех пор, пока каждый пиксель неразмытого контурного изображения
        не будет принадлежать какому-либо построенному лучу.</p>
    <p>В результате данного этапа обработки получаем так называемое SWT-изображение.
        При этом текстовые области явно отличаются от любых других областей, что можно увидеть ниже, на рис. 3.</p>

<img src="images/4/3.jpg" alt="Построение SWT-изображения" class="center">
        <p class="caption">Рисунок 3 – Построение SWT-изображения: а – исходное изображение, б – инвертированное
            контурное изображение, в – SWT-изображение</p>

    <br>
    <p>Особенностью метода обнаружения текстовых областей на этапе построения SWT-изображения
        является учет зависимости соотношения средней интенсивности цвета шрифта (Ic) и фона (Iф).
        При значении Ic/Iф &gt; 1 цвет шрифта считается светлее фона, следовательно, лучи следует строить
        от контуров символа к фону (рис. 3, а). В противном случае направление градиента меняется в
        обратную сторону и лучи строятся по направлению от фона к контуру символа (рис. 3, б).</p>
    <p>Использование двукратной SWT-обработки изображения для разного соотношения Ic/Iф с последующим
        объединением полученных результатов позволяет улучшить точность обнаружения текстовых областей на неоднородном
        фоне.</p>

<img src="images/4/4.jpg" alt="Варианты выбора направления обработки контурного изображения" class="center">
        <p class="caption">Рисунок 4 – Варианты выбора направления обработки контурного изображения: а – текст
            светлее фона; б – текст темнее фона</p>

    <h3>Этап 3. Фильтрация полученного SWT-изображения.</h3>
    <p>В начале этапа любая пара контуров проверяется на наличие общих точек.
        Если два контура не имеют ни одной общей точки – они считаются отдельными.
        В противном случае они объединяются в один контур.</p>
    <p>Для проверки принадлежности контура к символам рассчитывается среднее
        значение толщины штриха в этом контуре. Для каждого символа текста толщина
        штриха должна отличаться от среднего значения не более чем на 10 %. При превышении данного предела символ
        не будет считаться кандидатом на символ текста, соответствующая область изображения,
        ограниченная таким контуром, исключается из дальнейшей обработки.</p>
    <p>Для выделенных символов проверяется соотношение пропорций по формуле <i>c=h/w, </i>где h – высота символа, w –
        его ширина.</p>
    <p>При значениях с &gt;1,5 символ исключается из дальнейшего процесса обработки.</p>
    <h3>Этап 4. Полученные после фильтрации компоненты объединяются в строки, согласно координатам полученных
        символов.</h3>
    <p>Если координаты центров каких-либо кандидатов на символ находятся на одной
        либо прямоугольники, в которые вписаны выделенные символы, имеют общие стороны или
        отрезки, то рассматриваемые символы являются частью последовательности символов и должны быть объединены.</p>
    <p>В конечном итоге получаем объединенные в компоненты символы, готовые к последующему
        процессу классификации либо распознавания. При этом фон удаляется с изображения, остается
        только массив текстовых областей (region of interest, ROI).</p>
    <p>Для проверки эффективности предложенного метода, было разработано программное
        обеспечение (язык программирования С++, среда разработки Qt SDK, 4.8, библиотека OpenCV 2.4.2).
        Проведенное тестирование показало, что количество обнаруженных и впоследствии выделенных символов
        составляет 75…90 % от общего количества символов на изображениях. Снижение результатов правильного
        обнаружения и выделения символов связано с зависимостью метода в целом от параметров детектора границ
        Канни и сложностью получения качественного исходного изображения. Улучшить результат обнаружения и
        сегментации можно применением предварительной обработки изображения, но вычислительная сложность при этом
        увеличивается.</p>
    <p>Ниже приведена таблица с процентным соотношением обнаруженных символов для шрифтов,
        чаще всего используемых в документообороте и наружной рекламе.</p>
    <p><i>Таблица 1 - Зависимость количества обнаруженных символов от шрифта, используемого в надписи</i></p>
    <br>
    <table align="center" border="1" cellpadding="5" cellspacing="0" width="30%">
        <tbody>
        <tr>
            <td align="center">Название шрифта</td>
            <td align="center">Символов обнаружено, %</td>
        </tr>
        <tr>
            <td>Times New Roman</td>
            <td align="center">74,6</td>
        </tr>
        <tr>
            <td>Arial</td>
            <td align="center">85,0</td>
        </tr>
        <tr>
            <td>Calibri Regular</td>
            <td align="center">90,0</td>
        </tr>
        <tr>
            <td>Free Sans</td>
            <td align="center">86,2</td>
        </tr>
        <tr>
            <td>MS Sans Serif</td>
            <td align="center">85,1</td>
        </tr>
        <tr>
            <td>Courier Regular</td>
            <td align="center">85,0</td>
        </tr>
        <tr>
            <td>Helvetica Regular</td>
            <td align="center">84,1</td>
        </tr>
        </tbody>
    </table>
    <br>
    <p>Количество обнаруженных и выделенных символов зависит от особенностей алгоритма
        и шрифтов. В частности, символы шрифтов с засечками и переменной толщиной штриха
        (большие кегли Times New Roman), обнаруживались намного хуже. Этот недостаток могут
        частично устранить морфологические операции. Применение операции дилатации для светлых,
        либо эрозии - для темных шрифтов увеличивало количество обнаруженных символов на 10…15 %.</p>
    <p>Предложенный метод обнаружения текстовых областей и выделения символов с использование
        SWT-преобразования позволяет обнаружить и выделить в среднем 85 % символов на изображениях
        независимо от языка и размера шрифта, что доказывает его работоспособность в системах автоматического
        распознавания текста.
    </p>
    <p>Использование двукратной SWT-обработки для разного соотношения средней
        интенсивности цвета шрифта и фона позволяет улучшить точность обнаружения
        текстовых областей на неоднородном фоне.</p>

    <h3>Литература
    </h3>
    <ol>
        <li>
            Шапиро, Л. Компьютерное зрение / Л. Шапиро, Дж. Стокман. — Спб.: Бином. Лаборатория знаний. — 2006. — 752 с.
        </li>
        <li>
            Гонсалес, Р. Цифровая обработка изображений / Р. Гонсалес, Р. Вудс. — M.: Техносфера, 2006. — 1072 с.
        </li>
        <li>Cong, Y. Detecting Texts of Arbitrary Orientations in Natural Images [Electronic resource]. /
            [Y. Cong, B. Xiang, L. Wenyu and others]. — Lab of Neuro Imaging and Department of Computer Science,
            UCLA — http://www.loni.ucla.edu/~ztu/publication/cvpr12_textdetection.pdf — 10.05.2012.
        </li>
        <li>Николенко, А.А. Локализация характерных фрагментов изображения на основе двумерных вейвлет-фильтров.
            / А.А. Николенко, О.Ю. Бабилунга, В.Н. Зайковский // Вісник нац. техн. ун-ту &laquo;ХПІ&raquo;. Зб. наук. праць. —
            2011. — № 36. — С. 122 — 127.
        </li>
        <li>
            Николенко, А.А. Обнаружение текстовых областей в видеопоследовательностях / А.А.
            Николенко, Тьен Т.К.Нгуен // Искусственный интеллект. — 2012. — № 4. — С. 227 — 234.
        </li>
        <li>Epshtein, B. Detecting Text in Natural Scenes with Stroke Width Transform [Electronic resource] / B.
            Epshtein, E. Ofek, Y. Wexler. — Microsoft Corporation, 2009. — http://research.microsoft.com/
            pubs/149305/1509.pdf. — 2010. — 23.12.12.
        </li>

    </ol>
    <h3>References
    </h3>
    <ol>
        <li>
            Shapiro, L. Komp'juternoe zrenie [Computer vision] / L. Shapiro, Dzh. Stokman. – St.-Petersburg. – 2006. –
            752 p.
        </li>
        <li>
            Gonsales, R. Cifrovaja obrabotka izobrazhenij [Digital image processing] / R. Gonsales, R. Vuds. – Moscow. –
            2006. – 1072 p.
        </li>
        <li>Cong, Y. Detecting Texts of Arbitrary Orientations in Natural Images [Electronic resource] / [Y. Cong, B.
            Xiang, L. Wenyu and other]. – Lab of Neuro Imaging and Department of Computer Science, UCLA –
            http://www.loni.ucla.edu/~ztu/publication/cvpr12_textdetection.pdf – 10.05.2012.
        </li>
        <li>Nikolenko, A.A. Lokalizacija harakternyh fragmentov izobrazhenija na osnove dvumernyh wavelet-fil'trov
            [Localization of specific image fragments based on two-dimensional wavelet filters ] // A.A. Nikolenko,
            О.Yu. Babilungaа, V.N. Zajkovskij // Vіsnik nac. tehn. un-tu &laquo;KhPI&raquo;. Sb. nauk. prac. – 2011. – 36. pp.
            122-127.
        </li>
        <li>
            Nikolenko, A.A. Obnaruzhenie tekstovih oblastej v videoposledovatelnostyah [Text regions detection in video
            frames] / A.A. Nikolenko, Tien T.K. Nguyen // Iskusstvennij intellect [Аrtificial intelligence].–2012 .– 4.
            –pp. 227-234.
        </li>
        <li>Epshtein, B. Detecting Text in Natural Scenes with Stroke Width Transform [Electronic resource] / B.
            Epshtein, E. Ofek, Y. Wexler. – Microsoft Corporation, 2009. – http://research.microsoft.com/
            pubs/149305/1509.pdf. – 2010. – 23.12.12.
        </li>
    </ol>
</body>
</html>